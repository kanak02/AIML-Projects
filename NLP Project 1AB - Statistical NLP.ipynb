{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a00f7b-8dac-42bb-ae26-66168c50f7cb",
   "metadata": {},
   "source": [
    "# Statistical NLP Part A (run on GL Bot.json)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a07f5a5-02e6-4ad0-96c0-c2dfdc0e0330",
   "metadata": {},
   "source": [
    "• DOMAIN: Digital content management\n",
    "• CONTEXT: Classification is probably the most popular task that you would deal with in real life. Text in the form of blogs, posts, articles, etc.\n",
    "are written every second. It is a challenge to predict the information about the writer without knowing about him/her. We are going to create a\n",
    "classifier that predicts multiple features of the author of a given text. We have designed it as a Multi label classification problem.\n",
    "• DATA DESCRIPTION: Over 600,000 posts from more than 19 thousand bloggers The Blog Authorship Corpus consists of the collected posts of\n",
    "19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or\n",
    "approximately 35 posts and 7250 words per person. Each blog is presented as a separate file, the name of which indicates a blogger id# and\n",
    "the blogger’s self-provided gender, age, industry, and astrological sign. (All are labelled for gender and age but for many, industry and/or sign is\n",
    "marked as unknown.) All bloggers included in the corpus fall into one of three age groups:\n",
    "• 8240 \"10s\" blogs (ages 13-17),\n",
    "• 8086 \"20s\" blogs(ages 23-27) and\n",
    "• 2994 \"30s\" blogs (ages 33-47)\n",
    "• For each age group, there is an equal number of male and female bloggers. Each blog in the corpus includes at least 200 occurrences of\n",
    "common English words. All formatting has been stripped with two exceptions. Individual posts within a single blogger are separated by the\n",
    "date of the following post and links within a post are denoted by the label url link.\n",
    "• PROJECT OBJECTIVE: To build a NLP classifier which can use input text parameters to determine the label/s of the blog. Specific to this case\n",
    "study, you can consider the text of the blog: ‘text’ feature as independent variable and ‘topic’ as dependent variable."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e437c65-1d70-4acf-9596-4f530666bb6e",
   "metadata": {},
   "source": [
    "Note to Evaluator:  My system configuration is not enough to run the blogs.zip data. So, I have done the Part A of assignment using the GL Bot.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b53897c-79f1-49dc-bc89-d3b179f5b722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kanak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kanak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import random\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Download NLTK data (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ebdf4c-1729-46d7-8875-14714398f0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of intents: 8\n",
      "First intent: {'tag': 'Intro', 'patterns': ['hi', 'how are you', 'is anyone there', 'hello', 'whats up', 'hey', 'yo', 'listen', 'please help me', 'i am learner from', 'i belong to', 'aiml batch', 'aifl batch', 'i am from', 'my pm is', 'blended', 'online', 'i am from', 'hey ya', 'talking to you for first time'], 'responses': ['Hello! how can i help you ?'], 'context_set': ''}\n"
     ]
    }
   ],
   "source": [
    "#1. Read and Analyse Dataset.\n",
    "# Load the JSON file\n",
    "file_path = 'GL Bot.json'  # File path\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Inspecting the data structure\n",
    "intents = data['intents']  # Accessing the intents from the JSON\n",
    "\n",
    "# Printing the first intent to understand the structure\n",
    "print(f\"Number of intents: {len(intents)}\")\n",
    "print(f\"First intent: {intents[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea17d35-6baf-46e3-9889-18bed14af2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Patterns and Tags:\n",
      "Pattern: hi, Tag: Intro\n",
      "Pattern: how are you, Tag: Intro\n",
      "Pattern: is anyone there, Tag: Intro\n",
      "Pattern: hello, Tag: Intro\n",
      "Pattern: whats up, Tag: Intro\n"
     ]
    }
   ],
   "source": [
    "#2. Preprocess unstructured data to make it consumable for model training.\n",
    "\n",
    "# Initialize lists to store patterns and tags\n",
    "patterns = []\n",
    "tags = []\n",
    "\n",
    "# Loop through each intent\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        # Tokenize each pattern\n",
    "        word_list = nltk.word_tokenize(pattern)\n",
    "        # Lemmatize each word and convert to lowercase\n",
    "        words = [lemmatizer.lemmatize(w.lower()) for w in word_list]\n",
    "        patterns.append(\" \".join(words))\n",
    "        tags.append(intent['tag'])\n",
    "\n",
    "# Print the first 5 preprocessed patterns and their tags\n",
    "print(\"Preprocessed Patterns and Tags:\")\n",
    "for i in range(5):\n",
    "    print(f\"Pattern: {patterns[i]}, Tag: {tags[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d250063-b6b5-4a45-8210-bade1baebccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (102, 157), Testing data shape: (26, 157)\n"
     ]
    }
   ],
   "source": [
    "#3C. Vectorize data using any one vectorizer.\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the patterns into a vectorized form\n",
    "X = vectorizer.fit_transform(patterns).toarray()\n",
    "\n",
    "# Convert tags into numerical labels for classification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(tags)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shape of the training and testing data\n",
    "print(f\"Training data shape: {X_train.shape}, Testing data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32b983d5-e010-476d-a84a-3b698a8054ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D. Build a base model for Supervised Learning\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8797b740-1b49-439a-8e54-8f1f3c7fd54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bot       1.00      0.50      0.67         2\n",
      "        Exit       0.33      0.33      0.33         3\n",
      "       Intro       0.50      0.40      0.44         5\n",
      "          NN       0.60      0.50      0.55         6\n",
      "     Olympus       0.67      0.67      0.67         3\n",
      "     Profane       0.00      0.00      0.00         2\n",
      "          SL       0.33      0.75      0.46         4\n",
      "      Ticket       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.43      0.39      0.39        26\n",
      "weighted avg       0.48      0.46      0.45        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#3E. Clearly print Performance Metrics.\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8ad1ade-e0c0-4b57-b21d-4c124af18582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bot       1.00      0.50      0.67         2\n",
      "        Exit       0.50      0.33      0.40         3\n",
      "       Intro       0.67      0.40      0.50         5\n",
      "          NN       1.00      0.50      0.67         6\n",
      "     Olympus       1.00      0.33      0.50         3\n",
      "     Profane       0.00      0.00      0.00         2\n",
      "          SL       0.25      1.00      0.40         4\n",
      "      Ticket       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.55      0.38      0.39        26\n",
      "weighted avg       0.65      0.46      0.47        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#4. Improve Performance of model.\n",
    "#4A. Experiment with other vectorisers.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the patterns into a TF-IDF matrix\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(patterns).toarray()\n",
    "\n",
    "# Split the TF-IDF data into training and testing sets\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Naive Bayes classifier on the TF-IDF features\n",
    "model_tfidf = MultinomialNB()\n",
    "model_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Make predictions on the test data (TF-IDF)\n",
    "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Classification Report (TF-IDF):\")\n",
    "print(classification_report(y_test_tfidf, y_pred_tfidf, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba12ff7e-059e-4b54-baec-a0ec25d046f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (SVM with TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bot       1.00      0.50      0.67         2\n",
      "        Exit       0.25      0.33      0.29         3\n",
      "       Intro       0.40      0.40      0.40         5\n",
      "          NN       0.75      0.50      0.60         6\n",
      "     Olympus       1.00      0.67      0.80         3\n",
      "     Profane       0.00      0.00      0.00         2\n",
      "          SL       0.40      1.00      0.57         4\n",
      "      Ticket       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.47      0.42      0.42        26\n",
      "weighted avg       0.53      0.50      0.48        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#4B. Build classifier Models using other algorithms than base model.\n",
    "# Using Support Vector Machine (SVM)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Train the SVM classifier on the TF-IDF features\n",
    "svm_model.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the SVM model's performance\n",
    "print(\"Classification Report (SVM with TF-IDF):\")\n",
    "print(classification_report(y_test_tfidf, y_pred_svm, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb505df4-4a7f-4c1e-8b04-872cd2916dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Random Forest with TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bot       1.00      0.50      0.67         2\n",
      "        Exit       0.33      0.33      0.33         3\n",
      "       Intro       0.40      0.40      0.40         5\n",
      "          NN       0.50      0.67      0.57         6\n",
      "     Olympus       1.00      0.67      0.80         3\n",
      "     Profane       0.00      0.00      0.00         2\n",
      "          SL       0.60      0.75      0.67         4\n",
      "      Ticket       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.48      0.41      0.43        26\n",
      "weighted avg       0.52      0.50      0.49        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#4B. Build classifier Models using other algorithms than base model.\n",
    "# Using Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Random Forest classifier on the TF-IDF features\n",
    "rf_model.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the Random Forest model's performance\n",
    "print(\"Classification Report (Random Forest with TF-IDF):\")\n",
    "print(classification_report(y_test_tfidf, y_pred_rf, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24e3a399-0120-4c5b-98bb-fac64bc4474b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.238 total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.238 total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.238 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.238 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=scale, kernel=poly;, score=0.238 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=scale, kernel=poly;, score=0.238 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=scale, kernel=poly;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=scale, kernel=poly;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=scale, kernel=poly;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.238 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.238 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.238 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.238 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=auto, kernel=poly;, score=0.238 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=auto, kernel=poly;, score=0.238 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=auto, kernel=poly;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=auto, kernel=poly;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=auto, kernel=poly;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.524 total time=   0.0s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.571 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.450 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.429 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.429 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.300 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.350 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.429 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.429 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.350 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.400 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, gamma=auto, kernel=linear;, score=0.524 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, gamma=auto, kernel=linear;, score=0.571 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, gamma=auto, kernel=linear;, score=0.450 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, gamma=auto, kernel=linear;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, gamma=auto, kernel=linear;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.238 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.238 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=auto, kernel=poly;, score=0.238 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=auto, kernel=poly;, score=0.238 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=auto, kernel=poly;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=auto, kernel=poly;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=auto, kernel=poly;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.524 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.571 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.450 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.476 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.524 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.350 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.450 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.429 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.429 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.350 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.400 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, gamma=auto, kernel=linear;, score=0.524 total time=   0.0s\n",
      "[CV 2/5] END ...C=10, gamma=auto, kernel=linear;, score=0.571 total time=   0.0s\n",
      "[CV 3/5] END ...C=10, gamma=auto, kernel=linear;, score=0.450 total time=   0.0s\n",
      "[CV 4/5] END ...C=10, gamma=auto, kernel=linear;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END ...C=10, gamma=auto, kernel=linear;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.238 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.238 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.250 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=auto, kernel=poly;, score=0.238 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=auto, kernel=poly;, score=0.238 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=auto, kernel=poly;, score=0.250 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=auto, kernel=poly;, score=0.250 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=auto, kernel=poly;, score=0.250 total time=   0.0s\n",
      "Best parameters for SVM: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Classification Report (Tuned SVM with TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bot       1.00      0.50      0.67         2\n",
      "        Exit       0.25      0.33      0.29         3\n",
      "       Intro       0.40      0.40      0.40         5\n",
      "          NN       0.75      0.50      0.60         6\n",
      "     Olympus       1.00      0.67      0.80         3\n",
      "     Profane       0.00      0.00      0.00         2\n",
      "          SL       0.40      1.00      0.57         4\n",
      "      Ticket       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.47      0.42      0.42        26\n",
      "weighted avg       0.53      0.50      0.48        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#4C. Tune Parameters/Hyperparameters of the model/s.\n",
    "# Hyperparameter Tuning for SVM using GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for SVM\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with SVM\n",
    "svm_grid = GridSearchCV(SVC(), svm_param_grid, refit=True, verbose=3, cv=5)\n",
    "\n",
    "# Fit the model\n",
    "svm_grid.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best parameters for SVM: {svm_grid.best_params_}\")\n",
    "\n",
    "# Make predictions with the best SVM model\n",
    "y_pred_svm_tuned = svm_grid.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the tuned SVM model's performance\n",
    "print(\"Classification Report (Tuned SVM with TF-IDF):\")\n",
    "print(classification_report(y_test_tfidf, y_pred_svm_tuned, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf1726c-672d-4be6-a480-aeb5273cc6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.476 total time=   0.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.476 total time=   0.0s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.400 total time=   0.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.450 total time=   0.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.381 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.429 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.300 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.500 total time=   0.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300;, score=0.429 total time=   0.9s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300;, score=0.429 total time=   0.8s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300;, score=0.350 total time=   0.8s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300;, score=0.650 total time=   0.6s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300;, score=0.500 total time=   0.9s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.381 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.476 total time=   0.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.350 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.650 total time=   0.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.500 total time=   0.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.381 total time=   0.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.429 total time=   0.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.400 total time=   0.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.650 total time=   0.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.450 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.381 total time=   1.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.429 total time=   0.8s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.350 total time=   1.0s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.600 total time=   0.9s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.500 total time=   0.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.333 total time=   0.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.571 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.300 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.600 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.500 total time=   0.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.381 total time=   0.6s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.429 total time=   0.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.300 total time=   0.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.650 total time=   0.6s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.500 total time=   0.6s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.381 total time=   0.8s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.429 total time=   1.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.300 total time=   0.7s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.700 total time=   0.7s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.450 total time=   0.8s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.381 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.381 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.300 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.450 total time=   0.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.350 total time=   0.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.381 total time=   0.3s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.429 total time=   0.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.350 total time=   0.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.700 total time=   0.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.350 total time=   0.6s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.381 total time=   0.8s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.381 total time=   0.6s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.350 total time=   0.7s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.600 total time=   0.6s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.400 total time=   0.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.429 total time=   0.3s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.381 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.300 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.650 total time=   0.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.400 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.429 total time=   0.5s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.429 total time=   0.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.300 total time=   0.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.550 total time=   0.3s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.400 total time=   0.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.381 total time=   0.9s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.429 total time=   0.9s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.350 total time=   0.7s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.600 total time=   0.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.350 total time=   0.6s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.381 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.300 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.500 total time=   0.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.450 total time=   0.1s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.429 total time=   0.3s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.381 total time=   0.2s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.300 total time=   0.4s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.650 total time=   0.3s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.400 total time=   0.5s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.429 total time=   0.8s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.381 total time=   0.8s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.300 total time=   0.7s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.550 total time=   0.7s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.450 total time=   0.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.286 total time=   0.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.238 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.250 total time=   0.2s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.250 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.238 total time=   0.5s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.286 total time=   0.3s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.250 total time=   0.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.250 total time=   0.6s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.250 total time=   0.5s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300;, score=0.238 total time=   1.2s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300;, score=0.238 total time=   0.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300;, score=0.250 total time=   0.7s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300;, score=0.250 total time=   1.0s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300;, score=0.350 total time=   0.7s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.238 total time=   0.1s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.286 total time=   0.1s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.350 total time=   0.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.250 total time=   0.2s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.238 total time=   0.3s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.333 total time=   0.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.250 total time=   0.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.350 total time=   0.3s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.250 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.238 total time=   1.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.238 total time=   0.9s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.250 total time=   0.8s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.250 total time=   0.7s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.250 total time=   1.0s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.238 total time=   0.4s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.238 total time=   0.4s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.250 total time=   0.2s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.350 total time=   0.1s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.250 total time=   0.4s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.238 total time=   0.3s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.238 total time=   0.5s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.250 total time=   0.3s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.250 total time=   0.4s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.350 total time=   0.3s\n",
      "[CV 1/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.286 total time=   1.0s\n",
      "[CV 2/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.238 total time=   0.6s\n",
      "[CV 3/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.250 total time=   0.5s\n",
      "[CV 4/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.250 total time=   0.6s\n",
      "[CV 5/5] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.250 total time=   0.5s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.429 total time=   0.2s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.619 total time=   0.2s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.650 total time=   0.1s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.500 total time=   0.1s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.429 total time=   0.7s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.619 total time=   0.6s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.400 total time=   0.6s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.700 total time=   0.4s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.500 total time=   0.5s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300;, score=0.429 total time=   0.7s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300;, score=0.571 total time=   0.6s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300;, score=0.400 total time=   0.6s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300;, score=0.700 total time=   0.8s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300;, score=0.500 total time=   1.4s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.381 total time=   0.1s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.619 total time=   0.2s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.400 total time=   0.2s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.700 total time=   0.2s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.500 total time=   0.1s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.381 total time=   0.4s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.571 total time=   0.5s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.300 total time=   0.4s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.750 total time=   0.4s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.500 total time=   0.4s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.381 total time=   0.7s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.619 total time=   0.6s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.300 total time=   0.6s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.700 total time=   0.5s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.500 total time=   0.5s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.381 total time=   0.1s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.476 total time=   0.2s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.350 total time=   0.1s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.750 total time=   0.1s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.500 total time=   0.2s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.381 total time=   0.7s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.571 total time=   0.8s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.350 total time=   0.8s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.750 total time=   0.5s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.500 total time=   0.9s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.381 total time=   1.3s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.571 total time=   0.6s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.300 total time=   0.6s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.700 total time=   0.8s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.550 total time=   1.3s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.381 total time=   0.2s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.429 total time=   0.2s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.350 total time=   0.3s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.650 total time=   0.1s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.450 total time=   0.3s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.429 total time=   0.6s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.381 total time=   0.5s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.350 total time=   0.7s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.650 total time=   0.6s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.350 total time=   0.6s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.429 total time=   0.8s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.381 total time=   0.7s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.300 total time=   0.8s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.600 total time=   0.8s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.400 total time=   1.2s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.429 total time=   0.4s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.429 total time=   0.3s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.350 total time=   0.2s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.500 total time=   0.2s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.350 total time=   0.2s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.429 total time=   0.7s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.429 total time=   0.7s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.300 total time=   0.4s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.600 total time=   0.3s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.400 total time=   0.5s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.429 total time=   1.2s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.381 total time=   1.1s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.350 total time=   0.5s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.600 total time=   0.6s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.450 total time=   0.5s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.381 total time=   0.1s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.381 total time=   0.2s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.350 total time=   0.1s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.600 total time=   0.2s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.450 total time=   0.1s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.381 total time=   0.3s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.429 total time=   0.3s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.350 total time=   0.3s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.650 total time=   0.3s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.450 total time=   0.4s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.333 total time=   0.5s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.381 total time=   0.6s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.350 total time=   0.6s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.500 total time=   0.6s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.450 total time=   0.8s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.286 total time=   0.2s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.350 total time=   0.1s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.286 total time=   0.3s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.238 total time=   0.4s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.250 total time=   0.3s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.250 total time=   0.3s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.250 total time=   0.3s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300;, score=0.286 total time=   0.4s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300;, score=0.238 total time=   0.5s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300;, score=0.250 total time=   0.5s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300;, score=0.250 total time=   0.5s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300;, score=0.250 total time=   0.5s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.238 total time=   0.1s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.238 total time=   0.1s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.300 total time=   0.1s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.350 total time=   0.1s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.238 total time=   0.3s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.286 total time=   0.3s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.250 total time=   0.3s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.350 total time=   0.3s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.250 total time=   0.3s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.238 total time=   0.5s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.238 total time=   0.6s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.250 total time=   0.5s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.250 total time=   0.5s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.250 total time=   0.5s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.238 total time=   0.1s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.238 total time=   0.1s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.238 total time=   0.3s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.238 total time=   0.4s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.300 total time=   0.5s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.350 total time=   0.4s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.250 total time=   0.4s\n",
      "[CV 1/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.238 total time=   0.7s\n",
      "[CV 2/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.333 total time=   0.6s\n",
      "[CV 3/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.250 total time=   0.5s\n",
      "[CV 4/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.250 total time=   0.5s\n",
      "[CV 5/5] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.250 total time=   0.5s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.429 total time=   0.2s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.571 total time=   0.1s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.400 total time=   0.1s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.700 total time=   0.1s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.550 total time=   0.1s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.429 total time=   0.3s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.571 total time=   0.5s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.450 total time=   0.7s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.700 total time=   0.4s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.500 total time=   0.4s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300;, score=0.429 total time=   0.7s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300;, score=0.571 total time=   0.6s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300;, score=0.400 total time=   0.5s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300;, score=0.700 total time=   0.5s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300;, score=0.500 total time=   0.5s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.381 total time=   0.2s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.571 total time=   0.1s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.700 total time=   0.1s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.500 total time=   0.1s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.381 total time=   0.5s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.571 total time=   0.4s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.400 total time=   0.3s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.750 total time=   0.4s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.500 total time=   0.4s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.429 total time=   1.0s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.571 total time=   1.0s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.350 total time=   0.7s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.700 total time=   0.6s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.500 total time=   0.5s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.381 total time=   0.1s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.571 total time=   0.1s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.350 total time=   0.1s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.750 total time=   0.2s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.500 total time=   0.1s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.381 total time=   0.5s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.571 total time=   0.5s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.250 total time=   0.4s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.750 total time=   0.4s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.500 total time=   0.4s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.381 total time=   0.6s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.571 total time=   0.6s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.300 total time=   0.6s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.700 total time=   0.6s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.500 total time=   0.6s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.381 total time=   0.1s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.429 total time=   0.1s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.350 total time=   0.1s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.550 total time=   0.1s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.450 total time=   0.1s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.381 total time=   0.3s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.429 total time=   0.3s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.400 total time=   0.4s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.550 total time=   0.4s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.450 total time=   0.3s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.429 total time=   0.5s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.429 total time=   0.7s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.350 total time=   0.5s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.550 total time=   0.6s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.450 total time=   0.5s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.429 total time=   0.1s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.381 total time=   0.1s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.300 total time=   0.1s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.650 total time=   0.1s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.400 total time=   0.1s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.429 total time=   0.3s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.429 total time=   0.3s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.350 total time=   0.3s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.550 total time=   0.2s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.350 total time=   0.3s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.333 total time=   0.6s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.381 total time=   0.9s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.300 total time=   0.6s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.550 total time=   0.5s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.400 total time=   0.6s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.429 total time=   0.2s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.381 total time=   0.1s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.300 total time=   0.1s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.550 total time=   0.2s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.350 total time=   0.2s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.286 total time=   0.4s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.381 total time=   0.3s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.400 total time=   0.4s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.500 total time=   0.4s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.450 total time=   0.6s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.429 total time=   0.5s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.381 total time=   0.4s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.300 total time=   0.4s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.700 total time=   0.4s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.400 total time=   0.5s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.238 total time=   0.1s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.333 total time=   0.1s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.250 total time=   0.2s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.250 total time=   0.3s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.350 total time=   0.1s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.238 total time=   0.3s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.238 total time=   0.3s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.250 total time=   0.4s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.250 total time=   0.4s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.350 total time=   0.5s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300;, score=0.238 total time=   0.5s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300;, score=0.238 total time=   0.4s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300;, score=0.250 total time=   0.5s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300;, score=0.250 total time=   0.5s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300;, score=0.250 total time=   0.7s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.238 total time=   0.1s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.333 total time=   0.4s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.350 total time=   0.1s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.350 total time=   0.1s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.238 total time=   0.5s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.238 total time=   0.2s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.250 total time=   0.3s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.300 total time=   0.3s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.250 total time=   0.3s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.238 total time=   0.5s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.238 total time=   0.6s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.250 total time=   0.6s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.250 total time=   0.6s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.250 total time=   0.7s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.286 total time=   0.1s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.238 total time=   0.1s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.300 total time=   0.1s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.250 total time=   0.1s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.350 total time=   0.1s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.286 total time=   0.3s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.238 total time=   0.3s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.250 total time=   0.3s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.250 total time=   0.3s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.250 total time=   0.2s\n",
      "[CV 1/5] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.286 total time=   0.5s\n",
      "[CV 2/5] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.238 total time=   0.5s\n",
      "[CV 3/5] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.250 total time=   0.5s\n",
      "[CV 4/5] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.250 total time=   0.7s\n",
      "[CV 5/5] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.250 total time=   0.7s\n",
      "Best parameters for Random Forest: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Classification Report (Tuned Random Forest with TF-IDF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bot       1.00      0.50      0.67         2\n",
      "        Exit       0.33      0.33      0.33         3\n",
      "       Intro       0.40      0.40      0.40         5\n",
      "          NN       0.50      0.67      0.57         6\n",
      "     Olympus       1.00      0.67      0.80         3\n",
      "     Profane       0.00      0.00      0.00         2\n",
      "          SL       0.60      0.75      0.67         4\n",
      "      Ticket       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.48      0.41      0.43        26\n",
      "weighted avg       0.52      0.50      0.49        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#4C. Tune Parameters/Hyperparameters of the model/s.\n",
    "# Hyperparameter Tuning for Random Forest using GridSearchCV\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with Random Forest\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(), rf_param_grid, refit=True, verbose=3, cv=5)\n",
    "\n",
    "# Fit the model\n",
    "rf_grid.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best parameters for Random Forest: {rf_grid.best_params_}\")\n",
    "\n",
    "# Make predictions with the best Random Forest model\n",
    "y_pred_rf_tuned = rf_grid.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the tuned Random Forest model's performance\n",
    "print(\"Classification Report (Tuned Random Forest with TF-IDF):\")\n",
    "print(classification_report(y_test_tfidf, y_pred_rf_tuned, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59b25242-ea2f-4b65-a1d9-45b8dd37a970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Summary:\n",
      "\n",
      "Naive Bayes with Count Vectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bot       1.00      0.50      0.67         2\n",
      "        Exit       0.33      0.33      0.33         3\n",
      "       Intro       0.50      0.40      0.44         5\n",
      "          NN       0.60      0.50      0.55         6\n",
      "     Olympus       0.67      0.67      0.67         3\n",
      "     Profane       0.00      0.00      0.00         2\n",
      "          SL       0.33      0.75      0.46         4\n",
      "      Ticket       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.43      0.39      0.39        26\n",
      "weighted avg       0.48      0.46      0.45        26\n",
      "\n",
      "\n",
      "Naive Bayes with TF-IDF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bot       1.00      0.50      0.67         2\n",
      "        Exit       0.50      0.33      0.40         3\n",
      "       Intro       0.67      0.40      0.50         5\n",
      "          NN       1.00      0.50      0.67         6\n",
      "     Olympus       1.00      0.33      0.50         3\n",
      "     Profane       0.00      0.00      0.00         2\n",
      "          SL       0.25      1.00      0.40         4\n",
      "      Ticket       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.55      0.38      0.39        26\n",
      "weighted avg       0.65      0.46      0.47        26\n",
      "\n",
      "\n",
      "SVM with TF-IDF (Before tuning):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bot       1.00      0.50      0.67         2\n",
      "        Exit       0.25      0.33      0.29         3\n",
      "       Intro       0.40      0.40      0.40         5\n",
      "          NN       0.75      0.50      0.60         6\n",
      "     Olympus       1.00      0.67      0.80         3\n",
      "     Profane       0.00      0.00      0.00         2\n",
      "          SL       0.40      1.00      0.57         4\n",
      "      Ticket       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.47      0.42      0.42        26\n",
      "weighted avg       0.53      0.50      0.48        26\n",
      "\n",
      "\n",
      "Tuned SVM with TF-IDF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bot       1.00      0.50      0.67         2\n",
      "        Exit       0.25      0.33      0.29         3\n",
      "       Intro       0.40      0.40      0.40         5\n",
      "          NN       0.75      0.50      0.60         6\n",
      "     Olympus       1.00      0.67      0.80         3\n",
      "     Profane       0.00      0.00      0.00         2\n",
      "          SL       0.40      1.00      0.57         4\n",
      "      Ticket       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.47      0.42      0.42        26\n",
      "weighted avg       0.53      0.50      0.48        26\n",
      "\n",
      "\n",
      "Random Forest with TF-IDF (Before tuning):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bot       1.00      0.50      0.67         2\n",
      "        Exit       0.33      0.33      0.33         3\n",
      "       Intro       0.40      0.40      0.40         5\n",
      "          NN       0.50      0.67      0.57         6\n",
      "     Olympus       1.00      0.67      0.80         3\n",
      "     Profane       0.00      0.00      0.00         2\n",
      "          SL       0.60      0.75      0.67         4\n",
      "      Ticket       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.48      0.41      0.43        26\n",
      "weighted avg       0.52      0.50      0.49        26\n",
      "\n",
      "\n",
      "Tuned Random Forest with TF-IDF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bot       1.00      0.50      0.67         2\n",
      "        Exit       0.33      0.33      0.33         3\n",
      "       Intro       0.40      0.40      0.40         5\n",
      "          NN       0.50      0.67      0.57         6\n",
      "     Olympus       1.00      0.67      0.80         3\n",
      "     Profane       0.00      0.00      0.00         2\n",
      "          SL       0.60      0.75      0.67         4\n",
      "      Ticket       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.48      0.41      0.43        26\n",
      "weighted avg       0.52      0.50      0.49        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#4D. Clearly print Performance Metrics.\n",
    "\n",
    "# Summary of models and vectorizers\n",
    "print(\"Model Performance Summary:\")\n",
    "\n",
    "# Naive Bayes with Count Vectorizer\n",
    "print(\"\\nNaive Bayes with Count Vectorizer:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Naive Bayes with TF-IDF\n",
    "print(\"\\nNaive Bayes with TF-IDF:\")\n",
    "print(classification_report(y_test_tfidf, y_pred_tfidf, target_names=label_encoder.classes_))\n",
    "\n",
    "# SVM with TF-IDF (Before tuning)\n",
    "print(\"\\nSVM with TF-IDF (Before tuning):\")\n",
    "print(classification_report(y_test_tfidf, y_pred_svm, target_names=label_encoder.classes_))\n",
    "\n",
    "# Tuned SVM with TF-IDF\n",
    "print(\"\\nTuned SVM with TF-IDF:\")\n",
    "print(classification_report(y_test_tfidf, y_pred_svm_tuned, target_names=label_encoder.classes_))\n",
    "\n",
    "# Random Forest with TF-IDF (Before tuning)\n",
    "print(\"\\nRandom Forest with TF-IDF (Before tuning):\")\n",
    "print(classification_report(y_test_tfidf, y_pred_rf, target_names=label_encoder.classes_))\n",
    "\n",
    "# Tuned Random Forest with TF-IDF\n",
    "print(\"\\nTuned Random Forest with TF-IDF:\")\n",
    "print(classification_report(y_test_tfidf, y_pred_rf_tuned, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e274f4ab-af15-4c61-abb8-433cd57bd08b",
   "metadata": {},
   "source": [
    "### 5. Share insights on relative performance comparison.\n",
    "### 5A. Which vectorizer performed better? Probable reason?\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2a3df48-b53a-406a-a60a-808bad6838b3",
   "metadata": {},
   "source": [
    "The TF-IDF Vectorizer generally performed better than the Count Vectorizer across all models. This is perhaps because TF-IDF considers the frequency of terms within a document (like Count Vectorizer) as well as weighs down commonly occurring less informative words (e.g., stopwords) while giving more weight to rarer terms that are more informative. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af947920-6e5a-41bd-b492-e6115c5037ae",
   "metadata": {},
   "source": [
    "### 5B. Which model outperformed? Probable reason?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56a6c99a-1d2b-4729-88ee-0ac194ab09a6",
   "metadata": {},
   "source": [
    "The SVM with TF-IDF performed slightly better than the Naive Bayes and Random Forest models in terms of the F1-score for several tags (e.g., \"Olympus\" and \"SL\"). SVMs tend to perform better on text classification tasks when the data has clear decision boundaries and sparse high-dimensional data, as is the case with TF-IDF features. Additionally, SVMs are good at handling imbalanced classes by maximizing the margin between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f280ae8-6969-4a59-bd9f-8fe1d7e3fa69",
   "metadata": {},
   "source": [
    "### 5C. Which parameter/hyperparameter significantly helped to improve performance?Probable reason?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6ab5872-8f28-4ba5-a511-008c033029b9",
   "metadata": {},
   "source": [
    "For SVM, the most significant hyperparameters that improved performance were the C (regularization) and kernel. The \"C\" parameter controls the trade-off between achieving a low error on the training data and minimizing the model complexity. A well-tuned \"C\" value prevents overfitting while maintaining good generalization performance. The kernel determines how the input data is transformed into a higher-dimensional space to better handle complex relationships.\n",
    "For Random Forest, the number of estimators (trees) and max depth were significant. Increasing the number of trees helps improve robustness and prevents overfitting by averaging multiple decision paths, while the depth controls the complexity of each tree, helping the model generalize better on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d79aa-4510-49f7-a6d5-51e517c79e62",
   "metadata": {},
   "source": [
    "### 5D. According to you, which performance metric should be given most importance, why?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b963dd9-cbef-49c3-b0f0-ff7b6cc8f1f5",
   "metadata": {},
   "source": [
    "For this classification task, where some classes have very few samples, Recall and F1-score should be given the most importance. Recall ensures that the model is not missing any true positives, which is particularly important when certain classes (e.g., \"Profane\" and \"Ticket\") are underrepresented. The F1-score is a harmonic mean of precision and recall, providing a balance between both metrics, making it a good choice when you want to balance precision and recall, especially in the presence of imbalanced data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
